{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop and Frisk in NYC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The New York Police Department publicly releases data concerning its use of \"stop & frisk\" each year. \"Stop & Frisk\" is the NYPD's practice of temporarily detaining, questioning, and at times searching civilians on the street for weapons and other contraband. The practice is controversial, as many claim it unfairly targets certain minorities and neighborhoods. For this analysis, I will combine the 2016 NYC Stop and Frisk data with the 2016 Economic Profile of NYC's NTAs. NTAs are Neighborhood Tabulation Areas as created by the NYC Department of City Planning using whole census tracts from the 2010 Census as building blocks. The model I will build will attempt to classify each NTA in 1 of 2 categories, above or below the median number of police stops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hypothesis:\n",
    "Areas that NYPD choose to use \"Stop & Frisk\" most often are ones that are less economically stable. Using economic data concerning the population living in each of NYC's Neighborhood Tabulation Areas, we can determine which neighborhoods of NYC are most targeted for stop and frisk.\n",
    "\n",
    "###### Data Sources:\n",
    "Stop and Frisk Data: https://data.cityofnewyork.us/Public-Safety/The-Stop-Question-and-Frisk-Data/ftxv-d5ix\n",
    "\n",
    "Economic Data: https://data.cityofnewyork.us/City-Government/Demographic-Social-Economic-and-Housing-Profiles-b/kvuc-fg9b\n",
    "\n",
    "NTA Data (to determine which NTA each police stop was in): https://data.cityofnewyork.us/City-Government/Neighborhood-Tabulation-Areas/cpf4-rkhq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import itertools\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "import plotly.figure_factory as ff\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly.tools.set_credentials_file(username='briansrebrenik', api_key='K6yV5ZOkcoPlllzkQsSb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briansrebrenik/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning:\n",
      "\n",
      "Columns (0,1,2,3,4,8,18,19,73,74,84,85,86,103,110,111) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "police_stops = pd.read_csv('sqf-2016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>pct</th>\n",
       "      <th>ser_num</th>\n",
       "      <th>datestop</th>\n",
       "      <th>timestop</th>\n",
       "      <th>recstat</th>\n",
       "      <th>inout</th>\n",
       "      <th>trhsloc</th>\n",
       "      <th>perobs</th>\n",
       "      <th>crimsusp</th>\n",
       "      <th>...</th>\n",
       "      <th>zip</th>\n",
       "      <th>addrpct</th>\n",
       "      <th>sector</th>\n",
       "      <th>beat</th>\n",
       "      <th>post</th>\n",
       "      <th>xcoord</th>\n",
       "      <th>ycoord</th>\n",
       "      <th>dettypCM</th>\n",
       "      <th>lineCM</th>\n",
       "      <th>detailCM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>41</td>\n",
       "      <td>22</td>\n",
       "      <td>2072016</td>\n",
       "      <td>100</td>\n",
       "      <td>A</td>\n",
       "      <td>O</td>\n",
       "      <td>P</td>\n",
       "      <td>1</td>\n",
       "      <td>BURG</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>41</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>1013353</td>\n",
       "      <td>234000</td>\n",
       "      <td>CM</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>2182016</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>P</td>\n",
       "      <td>8</td>\n",
       "      <td>MISDEMEANOR</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>D</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>983478</td>\n",
       "      <td>212373</td>\n",
       "      <td>CM</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>1012016</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>P</td>\n",
       "      <td>2</td>\n",
       "      <td>FEL</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>66</td>\n",
       "      <td>F</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>988340</td>\n",
       "      <td>172111</td>\n",
       "      <td>CM</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>47</td>\n",
       "      <td>18</td>\n",
       "      <td>1012016</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>FEL</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>47</td>\n",
       "      <td>C</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>CM</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>1012016</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>P</td>\n",
       "      <td>3</td>\n",
       "      <td>D.W.I.</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>79</td>\n",
       "      <td>G</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>998197</td>\n",
       "      <td>187413</td>\n",
       "      <td>CM</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year pct ser_num datestop timestop recstat inout trhsloc perobs  \\\n",
       "0  2016  41      22  2072016      100       A     O       P      1   \n",
       "1  2016  10      22  2182016       30       1     O       P      8   \n",
       "2  2016  66       1  1012016       30       1     I       P      2   \n",
       "3  2016  47      18  1012016       40       1     O       H      1   \n",
       "4  2016  79       1  1012016       50       1     O       P      3   \n",
       "\n",
       "      crimsusp   ...    zip addrpct sector beat post   xcoord   ycoord  \\\n",
       "0         BURG   ...             41      B    2       1013353   234000   \n",
       "1  MISDEMEANOR   ...             10      D             983478   212373   \n",
       "2          FEL   ...             66      F             988340   172111   \n",
       "3          FEL   ...             47      C                               \n",
       "4       D.W.I.   ...             79      G    4        998197   187413   \n",
       "\n",
       "  dettypCM lineCM detailCM  \n",
       "0       CM      1       14  \n",
       "1       CM      1       28  \n",
       "2       CM      1        9  \n",
       "3       CM      1       20  \n",
       "4       CM      1      112  \n",
       "\n",
       "[5 rows x 112 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_stops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12405 entries, 0 to 12404\n",
      "Columns: 112 entries, year to detailCM\n",
      "dtypes: object(112)\n",
      "memory usage: 10.6+ MB\n"
     ]
    }
   ],
   "source": [
    "police_stops.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The police data includes addresses for all of the stops. The NTA data gives the shape of each NTA by its coordinates. The function below is used to collect the coordinates of all of the police stops (using Google Maps API) so I can label each stop with the proper NTA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#API_key = *********\n",
    "def get_coordinates():\n",
    "    all_coordinates = []\n",
    "    for i in tqdm(range(len(police_stops))):\n",
    "        try:\n",
    "            sn = police_stops.stname.loc[i]\n",
    "            si = police_stops.stinter.loc[i]\n",
    "            cn = police_stops.city.loc[i]\n",
    "            r = requests.get(\n",
    "            f'https://maps.googleapis.com/maps/api/geocode/json?address={sn}+and+{si},+{cn},+NY&key={API_key}'\n",
    "            ).json()\n",
    "            coordinates = r['results'][0]['geometry']['location']\n",
    "            all_coordinates.append(coordinates)\n",
    "        except:\n",
    "            all_coordinates.append('NA')\n",
    "    return all_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coordinates = get_coordinates()\n",
    "# police_stops['coordinates'] = coordinates\n",
    "# police_stops.to_csv('police_stops.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briansrebrenik/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning:\n",
      "\n",
      "Columns (1,2,3,4,5,9,19,20,74,75,85,86,87,104,111,112) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>year</th>\n",
       "      <th>pct</th>\n",
       "      <th>ser_num</th>\n",
       "      <th>datestop</th>\n",
       "      <th>timestop</th>\n",
       "      <th>recstat</th>\n",
       "      <th>inout</th>\n",
       "      <th>trhsloc</th>\n",
       "      <th>perobs</th>\n",
       "      <th>...</th>\n",
       "      <th>addrpct</th>\n",
       "      <th>sector</th>\n",
       "      <th>beat</th>\n",
       "      <th>post</th>\n",
       "      <th>xcoord</th>\n",
       "      <th>ycoord</th>\n",
       "      <th>dettypCM</th>\n",
       "      <th>lineCM</th>\n",
       "      <th>detailCM</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>41</td>\n",
       "      <td>22</td>\n",
       "      <td>2072016</td>\n",
       "      <td>100</td>\n",
       "      <td>A</td>\n",
       "      <td>O</td>\n",
       "      <td>P</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>1013353</td>\n",
       "      <td>234000</td>\n",
       "      <td>CM</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>{'lat': 40.81312200000001, 'lng': -73.8942721}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>2182016</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>P</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>D</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>983478</td>\n",
       "      <td>212373</td>\n",
       "      <td>CM</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>{'lat': 40.7475915, 'lng': -73.9980082}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>1012016</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>P</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>66</td>\n",
       "      <td>F</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>988340</td>\n",
       "      <td>172111</td>\n",
       "      <td>CM</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>{'lat': 40.6387311, 'lng': -73.9846689}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>47</td>\n",
       "      <td>18</td>\n",
       "      <td>1012016</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>C</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>CM</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'lat': 40.8839888, 'lng': -73.8421695}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>1012016</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>P</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>79</td>\n",
       "      <td>G</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>998197</td>\n",
       "      <td>187413</td>\n",
       "      <td>CM</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>{'lat': 40.6829528, 'lng': -73.93336649999999}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  year pct ser_num datestop timestop recstat inout trhsloc  \\\n",
       "0           0  2016  41      22  2072016      100       A     O       P   \n",
       "1           1  2016  10      22  2182016       30       1     O       P   \n",
       "2           2  2016  66       1  1012016       30       1     I       P   \n",
       "3           3  2016  47      18  1012016       40       1     O       H   \n",
       "4           4  2016  79       1  1012016       50       1     O       P   \n",
       "\n",
       "  perobs                       ...                       addrpct sector beat  \\\n",
       "0      1                       ...                            41      B    2   \n",
       "1      8                       ...                            10      D        \n",
       "2      2                       ...                            66      F        \n",
       "3      1                       ...                            47      C        \n",
       "4      3                       ...                            79      G    4   \n",
       "\n",
       "  post   xcoord   ycoord dettypCM lineCM detailCM  \\\n",
       "0       1013353   234000       CM      1       14   \n",
       "1        983478   212373       CM      1       28   \n",
       "2        988340   172111       CM      1        9   \n",
       "3                              CM      1       20   \n",
       "4        998197   187413       CM      1      112   \n",
       "\n",
       "                                      coordinates  \n",
       "0  {'lat': 40.81312200000001, 'lng': -73.8942721}  \n",
       "1         {'lat': 40.7475915, 'lng': -73.9980082}  \n",
       "2         {'lat': 40.6387311, 'lng': -73.9846689}  \n",
       "3         {'lat': 40.8839888, 'lng': -73.8421695}  \n",
       "4  {'lat': 40.6829528, 'lng': -73.93336649999999}  \n",
       "\n",
       "[5 rows x 114 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police_stops = pd.read_csv('police_stops.csv')\n",
    "police_stops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the_geom</th>\n",
       "      <th>BoroCode</th>\n",
       "      <th>BoroName</th>\n",
       "      <th>CountyFIPS</th>\n",
       "      <th>NTACode</th>\n",
       "      <th>NTAName</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>Shape_Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MULTIPOLYGON (((-73.94732672160586 40.62916656...</td>\n",
       "      <td>3</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>47</td>\n",
       "      <td>BK43</td>\n",
       "      <td>Midwood</td>\n",
       "      <td>27996.591274</td>\n",
       "      <td>3.579964e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MULTIPOLYGON (((-73.94193078816201 40.70072523...</td>\n",
       "      <td>3</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>47</td>\n",
       "      <td>BK75</td>\n",
       "      <td>Bedford</td>\n",
       "      <td>29992.919174</td>\n",
       "      <td>3.262983e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MULTIPOLYGON (((-73.89138023380268 40.86170058...</td>\n",
       "      <td>2</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>5</td>\n",
       "      <td>BX40</td>\n",
       "      <td>Fordham South</td>\n",
       "      <td>15878.272921</td>\n",
       "      <td>6.307284e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MULTIPOLYGON (((-73.9760493559142 40.631275905...</td>\n",
       "      <td>3</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>47</td>\n",
       "      <td>BK88</td>\n",
       "      <td>Borough Park</td>\n",
       "      <td>39247.227722</td>\n",
       "      <td>5.400502e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MULTIPOLYGON (((-73.90855790522774 40.65209593...</td>\n",
       "      <td>3</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>47</td>\n",
       "      <td>BK96</td>\n",
       "      <td>Rugby-Remsen Village</td>\n",
       "      <td>30957.853395</td>\n",
       "      <td>3.270695e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            the_geom  BoroCode  BoroName  \\\n",
       "0  MULTIPOLYGON (((-73.94732672160586 40.62916656...         3  Brooklyn   \n",
       "1  MULTIPOLYGON (((-73.94193078816201 40.70072523...         3  Brooklyn   \n",
       "2  MULTIPOLYGON (((-73.89138023380268 40.86170058...         2     Bronx   \n",
       "3  MULTIPOLYGON (((-73.9760493559142 40.631275905...         3  Brooklyn   \n",
       "4  MULTIPOLYGON (((-73.90855790522774 40.65209593...         3  Brooklyn   \n",
       "\n",
       "   CountyFIPS NTACode               NTAName    Shape_Leng    Shape_Area  \n",
       "0          47    BK43               Midwood  27996.591274  3.579964e+07  \n",
       "1          47    BK75               Bedford  29992.919174  3.262983e+07  \n",
       "2           5    BX40         Fordham South  15878.272921  6.307284e+06  \n",
       "3          47    BK88          Borough Park  39247.227722  5.400502e+07  \n",
       "4          47    BK96  Rugby-Remsen Village  30957.853395  3.270695e+07  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading coordinate info for NTAs\n",
    "nta = pd.read_csv('nynta.csv')\n",
    "nta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following steps involve labeling each police report with the proper NTA. Column \"the_geom\" in the NTA table above contains the shape of each NTA neighborhood. Using the Shapely Python package, I will convert these coordinates into polygon objects. Using this objects, I can determine which NTA's \"contain\" each police stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = []\n",
    "#using regex to pull coordinates of each NTA\n",
    "for i in range(len(nta)):\n",
    "    coord = re.findall('(-?\\d\\d.\\d*\\s-?\\d\\d.\\d*)', nta.the_geom.loc[i])\n",
    "    coord = [x.split() for x in coord]\n",
    "    coord = [(float(x[0]), float(x[1])) for x in coord]\n",
    "    shape.append(coord)\n",
    "#converting each array of coordinates into Polygon object\n",
    "shape = [Polygon(x) for x in shape]\n",
    "#dictionary of each NTA and its coordinates\n",
    "ntas = dict((x[0], x[1]) for x in zip(list(nta.NTAName), shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 7166/12405 [00:07<00:06, 801.67it/s] "
     ]
    }
   ],
   "source": [
    "reports_ntas = []\n",
    "for i in tqdm(range(len(police_stops))):\n",
    "    try:\n",
    "        lng = float(re.findall('(-?\\d{2}\\.\\d*)', police_stops.coordinates.loc[i])[1])\n",
    "        lat = float(re.findall('(-?\\d{2}\\.\\d*)', police_stops.coordinates.loc[i])[0])\n",
    "        coords = Point(lng, lat)\n",
    "        find = False\n",
    "        for x in ntas.keys():\n",
    "            if ntas[x].contains(coords):\n",
    "                reports_ntas.append(x)\n",
    "                find= True\n",
    "                break\n",
    "        if not find:\n",
    "            reports_ntas.append('NA')\n",
    "    except:\n",
    "        reports_ntas.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "police_stops['nta'] = reports_ntas\n",
    "police_stops.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bar Chart of Locations of Stop and Frisk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nta_stop_count = Counter(list(police_stops.nta))\n",
    "stop_counts = list(nta_stop_count.values())\n",
    "print(f'Median Stop Count: {np.median(stop_counts)}')\n",
    "print(f'Mean Stop Count: {np.mean(stop_counts)}')\n",
    "print(f'Std Stop Count: {np.std(stop_counts)}')\n",
    "print(f'Min Stop Count: {np.min(stop_counts)}')\n",
    "print(f'Max Stop Count: {np.max(stop_counts)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,30))\n",
    "plt.barh(y=list(nta_stop_count.keys()), width = list(nta_stop_count.values()),)\n",
    "plt.title('Number of Stop and Frisk per NTA - 2016', size=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining stop and frisk data with econ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = nta[['NTAName', 'BoroName']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['stop_count'] = np.zeros(len(combined_df))\n",
    "for i in range(len(combined_df)):\n",
    "    try:\n",
    "        stop_count = nta_stop_count[combined_df.NTAName.loc[i]]\n",
    "        combined_df['stop_count'].loc[i] = stop_count\n",
    "    except:\n",
    "        combined_df['stop_count'].loc[i] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "econ_stats = pd.read_excel('econ_2016acs5yr_nta.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the following columns from econ data: % of civilian labor force unemployed, % using public transportation to get to work, mean travel time to work,  % employed in service industry, % in management/business industry, % in sales, % in construction, % in production/transportation, median household income, mean household income, % of household with SNAP benefits, % of housholds with cash public assistance income, % with health insurance coverage,  % of families below poverty level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "econ_stats = econ_stats[['GeogName', 'CvLFUEm2P', 'CW_PbTrnsP', 'MnTrvTmE', 'MgBSciArtP', 'SrvcP', 'SalesOffP', \n",
    " 'NRCnstMntP', 'PrdTrnsMMP', 'MdHHIncE', 'MnHHIncE', 'Inc_SNAPP', 'Inc_CPbAP', 'HInsP', 'FamBwPvP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df.set_index('NTAName').join(econ_stats.set_index('GeogName'), how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.rename(columns={'CvLFUEm2P': 'percent_unemployed', 'CW_PbTrnsP': 'percent_public_transportation', \n",
    "                            'MnTrvTmE': 'mean_travel_time', 'MgBSciArtP': 'percent_business_industry', \n",
    "                            'SrvcP': 'percent_service_job', 'SalesOffP': 'percent_sales_job', \n",
    "                            'NRCnstMntP': 'percent_construction_job', 'PrdTrnsMMP': 'percent_transportation_job', \n",
    "                            'MdHHIncE': 'median_income', 'MnHHIncE': 'mean_income', \n",
    "                            'Inc_SNAPP': 'percent_snap', 'Inc_CPbAP': 'percent_pub_assist', \n",
    "                            'HInsP': 'percent_with_health_ins', 'FamBwPvP': 'percent_below_pov'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "combined_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing Econ Data - Distribution of Median Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = combined_df.median_income[combined_df.BoroName == 'Manhattan']\n",
    "x2 = combined_df.median_income[combined_df.BoroName == 'Brooklyn']\n",
    "x3 = combined_df.median_income[combined_df.BoroName == 'Queens']  \n",
    "x4 = combined_df.median_income[combined_df.BoroName == 'Bronx']\n",
    "x5 = combined_df.median_income[combined_df.BoroName == 'Staten Island']\n",
    "# Group data together\n",
    "hist_data = [x1, x2, x3, x4, x5]\n",
    "\n",
    "group_labels = ['Manhattan', 'Brooklyn', 'Queens', 'Bronx', 'Staten Island']\n",
    "\n",
    "# Create distplot with custom bin_size\n",
    "fig = ff.create_distplot(hist_data, group_labels, bin_size=5000)\n",
    "\n",
    "# Plot!\n",
    "py.iplot(fig, filename='Distplot with Multiple Datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer, power_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting boro to categorical\n",
    "combined_df= pd.get_dummies(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.reset_index(inplace=True)\n",
    "combined_df.rename(columns= {'index': 'name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = combined_df.drop(columns=['stop_count', 'name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labeling NTAs based on whether they fall above or below median number of stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_median = np.median(combined_df.stop_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(len(combined_df)):\n",
    "    if combined_df.stop_count.loc[i] < stop_median:\n",
    "        labels.append(0)\n",
    "    else:\n",
    "        labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['target'] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr = combined_df.corr()\n",
    "\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "f, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "plt.title(\"Feature Correlation Heatmap\", fontsize = 30, color = \"#F97E77\")\n",
    "sns.heatmap(corr, mask=mask, cmap=plt.cm.Reds, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for Multicolinearity and removing excess features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.title(\"Regular Variables Correlation Heatmap\", fontsize = 18, color = \"#F97E77\")\n",
    "sns.heatmap(features.corr(), center = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop \"Mean Income\" since it has very high corelation with Median Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.drop(columns=['mean_income'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### encoding classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(combined_df[['target']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power Transform - transformation applied to make data more Gaussian-like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = power_transform(features, method= 'yeo-johnson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Random Forest Classifier Model\n",
    "A Random Forest Classifier is a type of ensemble model. It uses a modified tree learning algorithm that inspects, at each split in the learning process, a random subset of the features. The purpose of using an ensemble model is to combine weak models to obtain a high accuracy model.\n",
    "I chose this ensemble model for two primary reasons:\n",
    "1: Many of the features are highly correlated, so using many weak models with random selection of variables can help prevent overfitting. 2: Small number of observations and Random Forest uses multiple samples of the dataset, reducing the variance of the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, recall_score, accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, y, test_size= .2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(criterion='gini', n_estimators=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my model, I decided to use two different metrics, a confusion matrix and area under the curve.\n",
    "\n",
    "The confusion matrix is a table that summarizes how successful the classification model is at predicting examples for \n",
    "the two classes. In my confusion matrix below, the table is split into 4 quadrants representing True Positive, True Negative, False Positive and False Negative. From these numbers, we can calculate common classification metrics like accuracy and recall. For example, accuracy = TP + TN / TP + TN + FP + FN and recall = TP/ TP + FN. For this model, recall is especially important because we want to find those areas where stop and frisk happens more than the median (TP).\n",
    "\n",
    "Area under the ROC Curve uses a combination of True Positive Rate and False Positive Rate to summarize how well the model performs. The greater the AUC, the better the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'model recall score: {recall_score(y_test, preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'model accuracy score: {accuracy_score(y_test, preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    #Add Normalization Option\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix(y_test, rfc.predict(X_test)), classes=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, rfc.predict(X_test))\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "\n",
    "print('AUC: {}'.format(auc(fpr, tpr)))\n",
    "plt.figure(figsize=(10,8))\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.yticks([i/20.0 for i in range(21)])\n",
    "plt.xticks([i/20.0 for i in range(21)])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results of the model, it is clear that there is a correlation between the economic health of NYC neighborhoods and the amount of stop and frisk occurences in those neighborhoods. Certain economic features such as unemployment rate and percentage of households receiving SNAP benefits show a fair degree of correlation with number of police stops. However, the models recall score of .65 tells me that it finds it more difficult to find the true positives. One might infer from this that while poor economic environment does lead to increases in stop and frisk, there are neighborhoods with better economic statistics that also have higher number of stop and frisks. Further analysis would require looking into other factors including demographics and number of people who work in an NTA as opposed to living there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
